
# ChatGPT and privacy of data

In this document, I discuss two articles about ChatGPT, an "open-source chatbot", that maybe not be as safe as the user might consider it to be. I present two viewpoints on how ChatGPT might be unsafe and how it is tracking users' actions

## Article 1
### [Generative AI ChatGPT Can Disturbingly Gobble Up Your Private And Confidential Data, Forewarns AI Ethics And AI Law](https://www.forbes.com/sites/lanceeliot/2023/01/27/generative-ai-chatgpt-can-disturbingly-gobble-up-your-private-and-confidential-data-forewarns-ai-ethics-and-ai-law/?sh=667e5ff07fdb)
In this article, the writer explains how users are eagerly using ChatGPT, without realizing how their confidential information is accessible to the developers. Privacy of data is one of the controversial topics that are often in the news. The writer walks us through the process of how ChatGPT AI converts words into tokens. Each token is created again as a number, meaning the text entered is now a set of numbers. "Those numbers are used to computationally analyze the prompt. Ultimately, when composing or generating the outputted essay, these numeric tokens are first used, and then before being displayed, the tokens are converted back into sets of letters and words."(Article 1). The article emphasizes how data shared by the users can be used by AI trainers to improve the systems and services. The writers notify readers that any of the input text prompts and the related essays, which are all part of the "conversation" that you have with ChatGPT, can be completely observed by their trainers. The extent to which the developers can use the data provided by the users is uncertain. Companies to improve their product take the data and run their applications around it to engage the user as much as possible. The writer talked about how lawyers might use AI, to draft legal documents. While drafting documents they might share confidential data. This data is now available to trainers and AI developers.
<br>
The writer explains ways in which the data is getting shared, and the user might be unaware of it. The algorithms made by social media companies to have the users engage more with their application to increase their profits. ChatGPT has an addictive nature. If a student starts looking up their homework questions, after getting the answers, they keep on asking more.  The application makes the work of writing the question on the web, then going through each page and finding the answers, easier. The writer informs the reader to be careful with what information they are sharing while using the application. Agreeing with him, we have to be careful with the information that we are sharing while using ChatGPT because being users we are unaware of how our data might get used. We are unaware of the company's research and data manipulation procedures.

## Article 2
### [Uncovering the Hidden Risks of ChatGPT: Keeping Your Data Secure](https://medium.com/nextray-ai/uncovering-the-hidden-risks-of-chatgpt-keeping-your-data-secure-99911f3ed777#:~:text=ChatGPT%20is%20an%20open%2Dsource%20chatbot%2C%20which%20means%20anyone%20can,a%20vast%20amount%20of%20data.)
The writer in the article talks about how ChatGpt is not as secure as the users might believe it to be. The writer emphasized two main reasons why ChatGpt poses security risks if not used correctly. The first security risk that the writer discussed is related to cyberattacks. ChatGPT is an open-source chatbot, meaning the code used to make the application can be modified by anyone. Easy accessibility of the code makes it easy to edit and carry out cyberattacks. It stimulates conversations similar to how people text message each other. Users are constantly sharing their information, leading to risking their privacy. Agreeing with the writer, users like students often share their details to write essays, or companies share their details to get marketing content and presentation files. Data is getting shared, and users are unaware of it.  Another security risk that the writer emphasized is that ChatGPT can be used to spread malware. Malware leads to stealing personal information like credit card details, addresses, etc. 
<br>
New users unaware of the threats may be vulnerable to such attacks. The writer, in the end, discussed some steps that the user can take to safely use ChatGpt and protect themselves from any such attacks. Some of the steps included having two-factor authentication, having anti-virus software, etc. 